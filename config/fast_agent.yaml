# Fast-Agent Configuration for AI-Orchestration-Platform

execution_engine: asyncio
logger:
  type: file
  level: info
  path: logs/fast_agent.log

mcp:
  servers:
    # Basic MCP servers
    fetch:
      command: "npx"
      args: ["-y", "@modelcontextprotocol/server-fetch"]
    filesystem:
      command: "npx"
      args: ["-y", "@modelcontextprotocol/server-filesystem", "."]
    
    # Custom MCP servers for AI-Orchestration-Platform
    orchestrator:
      command: "python"
      args: ["-m", "src.fast_agent_integration.mcp_servers.orchestrator_server"]
      env:
        ORCHESTRATOR_API_KEY: "${ORCHESTRATOR_API_KEY}"

# LLM Provider configurations
llm:
  openai:
    api_key: "${OPENAI_API_KEY}"
    default_model: "gpt-4"
    timeout: 60
  
  anthropic:
    api_key: "${ANTHROPIC_API_KEY}"
    default_model: "claude-3-sonnet-20240229"
    timeout: 60

# Agent configurations
agents:
  default:
    name: "orchestrator_agent"
    instruction: "You are an AI orchestration agent that helps users with various tasks."
    servers: ["fetch", "filesystem", "orchestrator"]
    model: "${DEFAULT_LLM_MODEL:-gpt-4}"
  
  researcher:
    name: "researcher_agent"
    instruction: "You are a research agent that helps users find and analyze information."
    servers: ["fetch", "filesystem"]
    model: "${RESEARCHER_LLM_MODEL:-claude-3-sonnet-20240229}"
